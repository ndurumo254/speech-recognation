{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5cnn",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1glkEuvXJHzhVodQblYGeIWmBrHgy2YBS",
      "authorship_tag": "ABX9TyN3M5UBCiWvVv24I5VWNf1G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndurumo254/speech-recognation/blob/master/5cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVVjU7Fh1K-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1023
        },
        "outputId": "71870e05-986a-4871-d8c8-d15538bee17f"
      },
      "source": [
        "\n",
        "!!alias python='/usr/bin/python3.5\n",
        "!pip install q keras==2.1.6\n",
        "!pip install --ignore-installed --upgrade tensorflow==1.14\n",
        " "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: q in /usr/local/lib/python3.6/dist-packages (2.6)\n",
            "Requirement already satisfied: keras==2.1.6 in /usr/local/lib/python3.6/dist-packages (2.1.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.19.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.15.0)\n",
            "Collecting tensorflow==1.14\n",
            "  Using cached tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2 MB)\n",
            "Collecting grpcio>=1.8.6\n",
            "  Using cached grpcio-1.29.0-cp36-cp36m-manylinux2010_x86_64.whl (3.0 MB)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Using cached tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "Processing /root/.cache/pip/wheels/c3/af/84/3962a6af7b4ab336e951b7877dcfb758cf94548bb1771e0679/absl_py-0.9.0-py3-none-any.whl\n",
            "Processing /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc/termcolor-1.1.0-py3-none-any.whl\n",
            "Processing /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63/wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl\n",
            "Collecting gast>=0.2.0\n",
            "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Using cached tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "Collecting keras-preprocessing>=1.0.5\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "Collecting six>=1.10.0\n",
            "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting google-pasta>=0.1.6\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting astor>=0.6.0\n",
            "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting protobuf>=3.6.1\n",
            "  Using cached protobuf-3.12.2-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
            "Collecting wheel>=0.26\n",
            "  Using cached wheel-0.34.2-py2.py3-none-any.whl (26 kB)\n",
            "Collecting numpy<2.0,>=1.14.5\n",
            "  Using cached numpy-1.19.0-cp36-cp36m-manylinux2010_x86_64.whl (14.6 MB)\n",
            "Collecting setuptools>=41.0.0\n",
            "  Using cached setuptools-47.3.1-py3-none-any.whl (582 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Using cached Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
            "Collecting h5py\n",
            "  Using cached h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
            "Collecting importlib-metadata; python_version < \"3.8\"\n",
            "  Using cached importlib_metadata-1.6.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Using cached zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, grpcio, tensorflow-estimator, absl-py, termcolor, wrapt, gast, setuptools, protobuf, wheel, zipp, importlib-metadata, markdown, werkzeug, numpy, tensorboard, keras-preprocessing, h5py, keras-applications, google-pasta, astor, tensorflow\n",
            "Successfully installed absl-py-0.9.0 astor-0.8.1 gast-0.3.3 google-pasta-0.2.0 grpcio-1.29.0 h5py-2.10.0 importlib-metadata-1.6.1 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.2.2 numpy-1.19.0 protobuf-3.12.2 setuptools-47.3.1 six-1.15.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 werkzeug-1.0.1 wheel-0.34.2 wrapt-1.12.1 zipp-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "grpc",
                  "numpy",
                  "pkg_resources",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iubIyI9j1YRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "5d560366-43d0-4d3d-c794-c0540b9b25dc"
      },
      "source": [
        "import cv2\n",
        "import numpy\n",
        "import glob\n",
        "import pylab as plt\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RaYhWM51jKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convolution layer 1\n",
        "filter_size1=3 # convolutional filters are 3x3 pixels\n",
        "num_filters1= 32 #there are 16 of these filters\n",
        "#convolutional layer 2\n",
        "filter_size2=3 # convolutional filters are 3x3 pixels\n",
        "num_filters2= 32 #there are 16 of these filters\n",
        "#convolution layer 3\n",
        "filter_size3=3\n",
        "num_filters3=64\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rul_4NuJ1pXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fully connected layer\n",
        "fc_size=128 #number of neurns in fully connected layer\n",
        "num_channels=3\n",
        "img_size =128\n",
        "img_size_flat= img_size*img_size*num_channels\n",
        "\n",
        "img_shape=[374,388]\n",
        "epoch=500\n",
        "batch=20\n",
        "j=0\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vIak60H132E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folders = glob.glob('/content/drive/My Drive/ester/DB1_B/*')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LyffTw82Gql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a0dace6-6710-4ab1-8fff-ef4753c61301"
      },
      "source": [
        "len(folders)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL6ZXVQi2Phh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagenames_list = []\n",
        "labels =[]\n",
        "imagenames_list=[]\n",
        "count = 0\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZiBNqPZ2UN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for folder in folders:\n",
        "    for f in glob.glob(folder+'/*.tif'):\n",
        "        imagenames_list.append(f)\n",
        "        labels.append(count)\n",
        "    count+=1\n",
        "read_images=[]\n",
        "Tensor_input=[]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ewYckfx2iAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image in imagenames_list:\n",
        "    read_images.append(cv2.imread(image,cv2.IMREAD_GRAYSCALE))\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaNThnNc2m5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=tf.keras.utils.to_categorical(\n",
        "                 labels,\n",
        "                  num_classes=4\n",
        "                 )\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwQEBx5t2tkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_weights(shape):\n",
        "    return tf.Variable(tf.random.truncated_normal(shape, stddev=0.05))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ensgquz2zYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_biases(length):\n",
        "    return tf.Variable(tf.constant(0.05, shape=[length]))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6Fjzpct27VM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def new_conv_layer(\n",
        "                input,\n",
        "                num_input_channels,\n",
        "                filter_size,\n",
        "                num_filters,\n",
        "                use_pooling = True\n",
        "                ):\n",
        "    shape = [ filter_size,filter_size,num_input_channels,num_filters]\n",
        "\n",
        "    weights = new_weights(shape=shape)\n",
        "\n",
        "    biases = new_biases(length=num_filters)\n",
        "\n",
        "    layer =tf.nn.conv2d(\n",
        "                          input=input,\n",
        "                          filter= weights,\n",
        "                          strides=[1,1,1,1],\n",
        "                          padding='SAME'\n",
        "                        )\n",
        "    layer += biases\n",
        "    \n",
        "    if use_pooling:\n",
        "        layer= tf.nn.max_pool( value=layer,\n",
        "                               #input=layer,#modified from value\n",
        "                               ksize=[1,2,2,1],\n",
        "                               strides=[1,2,2,1],\n",
        "                               padding='SAME',\n",
        "                             )\n",
        "\n",
        "    layer = tf.nn.relu(layer)\n",
        "     \n",
        "\n",
        "\n",
        "    return layer,weights"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjXT-9jP3BPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten_layer(layer):\n",
        "    layer_shape = layer.get_shape()\n",
        "\n",
        "    num_features = layer_shape[1:4].num_elements()\n",
        "    layer_flat =tf.reshape(layer,[-1 , num_features])\n",
        "\n",
        "    return layer_flat,num_features"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgNmbFEz3Hdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_fc_layer(\n",
        "                 input,\n",
        "                 num_inputs,\n",
        "                 num_outputs,\n",
        "                 use_relu=True\n",
        "                 ):\n",
        "    weights= new_weights(shape=[num_inputs,num_outputs])\n",
        "    biases=new_biases(length=num_outputs)\n",
        "    layer =tf.matmul(input,weights) + biases\n",
        "    if use_relu:\n",
        "        layer =tf.nn.relu(layer)\n",
        "\n",
        "    return layer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmMJMcyh3M5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "x= tf.compat.v1.placeholder(tf.float32,shape=[None,374, 388],name='x')\n",
        "\n",
        "x_image = tf.reshape(x,[-1, 374,388,1])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vVjnUT-3RUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f721632-5ad0-49c1-efc9-24a6ce350e5f"
      },
      "source": [
        "print(x_image)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Reshape:0\", shape=(?, 374, 388, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shtGl_lO3XN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = tf.compat.v1.placeholder(tf.float32,shape=[None,10],name='y_true') \n",
        "y_true_cls = tf.argmax(y_true,axis=1)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhC-NoSR3cuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "layer_conv1,weights_conv1 =new_conv_layer(input=x_image,\n",
        "                                          num_input_channels=1,\n",
        "                                          num_filters=num_filters1,\n",
        "                                          filter_size=filter_size1,\n",
        "                                          use_pooling=True\n",
        "                                          )\n",
        "                                          \n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTffkga7MABv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_conv2,weights_conv2 =new_conv_layer(input=layer_conv1,\n",
        "                                          num_input_channels=num_filters1,\n",
        "                                          filter_size =filter_size2,\n",
        "                                          num_filters=num_filters2,\n",
        "                                          use_pooling= True)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knwk2vnENhFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d87a04de-1da5-4d61-e7a5-2043d08407db"
      },
      "source": [
        "print(layer_conv1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu:0\", shape=(?, 187, 194, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bhezfDJSmwu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4611ed40-04f4-47f8-e4ac-0920678c4df2"
      },
      "source": [
        "print(layer_conv2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_1:0\", shape=(?, 94, 97, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "110vHoSupRRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_flat,num_features =flatten_layer(layer_conv2)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHPwCCDUMLvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_fc1 = new_fc_layer(input=layer_flat,\n",
        "                         num_inputs=num_features,\n",
        "                         num_outputs=10,\n",
        "                         use_relu=True)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG6Eb8MjMguA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77bd9495-7497-417a-b5e9-672091f7956f"
      },
      "source": [
        "print(layer_fc1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_2:0\", shape=(?, 129), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m98d5A8LMR1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = tf.nn.softmax(layer_fc1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52Iv0fsRlnDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_d_x_hist =tf.summary.histogram('y_pred',y_pred)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e90cVfiXluga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "9172a4ee-6832-403d-b95d-cd94615c3082"
      },
      "source": [
        "y_pred_cls =tf.argmax(y_pred,axis=1)\n",
        "\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc1,\n",
        "                                                      labels=y_true)\n",
        "#cross_entropy=tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(\n",
        "   # labels, logits=layer_conv1, axis=None, name=None, dim=None\n",
        "#)\n",
        "#cross_entropy=tf.exp(logits=layer_conv1) / tf.reduce_sum(tf.exp(logits=layer_conv1), axis)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-29-e8a7ed74fc98>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqhGdBGdm31K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "summary_d_loss =tf.summary.scalar('cross_entropy',cross_entropy)\n",
        "cost = tf.reduce_mean(cross_entropy)\n",
        "summary_COST_loss =tf.summary.scalar('cost', cost)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmyuXd_A_7ej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "69da8b47-9101-407f-b4bf-149299127264"
      },
      "source": [
        "print(summary_d_loss)\n",
        "print(cost)\n",
        "print(summary_COST_loss)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"cross_entropy:0\", shape=(), dtype=string)\n",
            "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
            "Tensor(\"cost:0\", shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4xs5xQrm-G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_prediction = tf.equal(y_pred_cls,y_true_cls)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CavPd3sWOY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9909c49b-f7e8-4007-dda4-09e6fbfcf576"
      },
      "source": [
        "print(correct_prediction)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Equal:0\", shape=(?,), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h23uWMQvnEHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "summary_accuracy=tf.summary.scalar('accuracy',accuracy)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QU3nBp0WW6p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8a033070-8898-4d12-b89b-ba77d4eb6242"
      },
      "source": [
        "print(accuracy)\n",
        "print(summary_accuracy)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"accuracy:0\", shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i7WhzfQnLYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#optimizer = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(cost)\n",
        "optimizer=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nThvX5bnN7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81FvCr5lZZ0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Initializing the variables\n",
        "#init = tf.initialize_all_variables()\n",
        "init=tf.compat.v1.global_variables_initializer()\n",
        " "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYdxLEzz7ShB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a87a7aaa-4771-4577-8bb1-d9583466cd74"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "   sess.run(init)\n",
        "   saver=tf.train.Saver()\n",
        "   merged =tf.summary.merge_all()\n",
        "   writer = tf.summary.FileWriter('./logs',sess.graph)\n",
        "   for i in range(1,epoch):\n",
        "        batch_ss =read_images[j:batch+j]\n",
        "        labels_ss =labels[j:batch+j]\n",
        "\n",
        "        j+=batch\n",
        "        if j+batch>=len(read_images):\n",
        "            j=0\n",
        "\n",
        "        feed_dict_train = {x:batch_ss,\n",
        "                           y_true:labels_ss}\n",
        "\n",
        "        summary_loss,loss=sess.run([summary_COST_loss,cost],feed_dict=feed_dict_train)\n",
        "        summary_hist,prediction =sess.run([summary_d_x_hist,y_pred],feed_dict=feed_dict_train)\n",
        "        print (loss)\n",
        "        sess.run(optimizer,feed_dict=feed_dict_train)\n",
        "        summary_acc,acc = sess.run([summary_accuracy,accuracy],feed_dict_train)\n",
        "        if i%2==0:\n",
        "          acc =sess.run(accuracy,feed_dict=feed_dict_train)\n",
        "          msg =\"optimization iteration:{0:>6},Train Accuracy:{1:>6.1%}\"\n",
        "          print(msg.format(i + 1 , acc))\n",
        "        saver.save(sess,'./logs/model.ckpt',i) \n",
        "        writer.add_summary(summary_loss,global_step=i)\n",
        "        writer.add_summary(summary_acc,global_step=i)\n",
        "        writer.add_summary(summary_hist,global_step=i)\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-87f4850e94ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                            y_true:labels_ss}\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msummary_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msummary_COST_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0msummary_hist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msummary_d_x_hist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1149\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1150\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (0,) for Tensor 'x:0', which has shape '(?, 374, 388)'"
          ]
        }
      ]
    }
  ]
}